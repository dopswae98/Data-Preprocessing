{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab003046",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction\n",
    "\n",
    "This notebook performs data preprocessing, training, and evaluation of multiple machine learning models on the Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee1c18",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We start by loading the Titanic dataset into Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Titanic dataset\n",
    "train_df = pd.read_csv('./input/train.csv')\n",
    "test_df = pd.read_csv('./input/test.csv')\n",
    "\n",
    "print(\"Train Data Shape:\", train_df.shape)\n",
    "print(\"Test Data Shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf379b87",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We handle missing values, feature engineering, and encoding to prepare the dataset for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20056c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Age values with median age grouped by Pclass and Survived\n",
    "train_df['Age'] = train_df.groupby(['Pclass', 'Survived'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "test_df['Age'] = test_df.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill missing Embarked values with the most frequent value in train_df\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])\n",
    "test_df['Embarked'] = test_df['Embarked'].fillna(test_df['Embarked'].mode()[0])\n",
    "\n",
    "# Fill missing Fare values with the median\n",
    "test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median())\n",
    "\n",
    "# Apply transformations to both datasets\n",
    "for df in [train_df, test_df]:\n",
    "    df['Age'] = df.groupby(['Pclass'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df['AgeBin'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], labels=['Child', 'Teenager', 'Young Adult', 'Adult', 'Senior'])\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    for column in ['Sex', 'Embarked', 'AgeBin', 'Title']:\n",
    "        df[column] = label_encoder.fit_transform(df[column].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c89fcc",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Dropping unused columns to keep only the relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused columns, ensuring PassengerId is retained in test_df for submission purposes\n",
    "train_df.drop(['Ticket', 'Cabin', 'Name'], axis=1, inplace=True)\n",
    "test_df.drop(['Ticket', 'Cabin', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "# Define training and test datasets\n",
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test = test_df.drop(\"PassengerId\", axis=1).reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Verify matching columns\n",
    "print(\"Columns in X_train:\", X_train.columns)\n",
    "print(\"Columns in X_test:\", X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0148a2",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "We train a Decision Tree classifier and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree Classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on training data and evaluate\n",
    "train_pred = decision_tree.predict(X_train)\n",
    "print(f\"Training Accuracy: {accuracy_score(Y_train, train_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd1e20",
   "metadata": {},
   "source": [
    "## Comparing Multiple Models\n",
    "\n",
    "We train and compare multiple models to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Support Vector Machines\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Perceptron\": Perceptron(),\n",
    "    \"Stochastic Gradient Decent\": SGDClassifier(),\n",
    "    \"Linear SVC\": LinearSVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_train)\n",
    "    accuracies[name] = round(accuracy_score(Y_train, Y_pred) * 100, 2)\n",
    "\n",
    "# Store model performance in DataFrame\n",
    "models_df = pd.DataFrame(list(accuracies.items()), columns=[\"Model\", \"Score\"])\n",
    "models_df.sort_values(by=\"Score\", ascending=False, inplace=True)\n",
    "\n",
    "# Display results\n",
    "print(models_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea31fcd",
   "metadata": {},
   "source": [
    "## Predictions and Submission\n",
    "\n",
    "We generate predictions on the test set and save them for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45394f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "test_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Export predictions for submission\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_df[\"PassengerId\"],\n",
    "    \"Survived\": test_pred\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' created successfully!\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}